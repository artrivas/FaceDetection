El extractor de características base se empareja con el bloque de extracción de parches propuesto como nuestro intento de mejorar el rendimiento de FER en condiciones desafiantes. El bloque de extracción de parches está diseñado para extraer únicamente características locales.

El rendimiento de una ViT generalmente viene acompañado de arquitecturas grandes con significativamente más parámetros que los métodos basados en CNN. No obstante, el rendimiento bruto de la arquitectura ViT también atrajo nuestra atención para inspirarnos a integrar en la base MobileNetV1 para un mejor rendimiento en FER.

Aunque el bloque de extracción de parches está inspirado en ViT, existen algunas diferencias en términos de los detalles de implementación. La primera diferencia es el diseño y la ubicación del bloque de extracción de parches. El mecanismo de extracción de parches en ViT es una convolución de una sola capa que se coloca al comienzo de la arquitectura, mientras que el bloque de extracción de parches en el PAtt-Lite propuesto es una convolución de múltiples capas que se coloca dentro de la arquitectura. Esta ubicación permite que el método propuesto utilice completamente los pesos preentrenados del backbone MobileNetV1, que fueron entrenados con muestras de ImageNet de tamaño 224×224. En segundo lugar, ViT divide

En este artículo, se propone un clasificador de atención inspirado en la arquitectura Transformer para mejorar aún más el aprendizaje de los mapas de características de salida del extractor de características ligero modificado.

Específicamente, el clasificador de atención propuesto intenta replicar el rendimiento de los transformadores de visión sin requerir su serie de bloques de auto-atención. En su lugar, se integra una operación de auto-atención por producto punto entre las capas completamente conectadas del clasificador. A través de esta decisión de diseño, el modelo se puede mantener ligero mientras se conserva un alto rendimiento en la extracción de características y clasificación para la FER.